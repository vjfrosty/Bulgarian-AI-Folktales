{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Test DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-QX2WIwMC3mrFd3nN6PKa1ixf8jbggqFN0_MEa77QscT3BlbkFJKyseiOomj_PaASe5L8gkKJ-tdslbAznXpOVAzQsNoA\n",
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "заекът спасител: един човек отишъл да оре. видяла го една мечка, отишла на нивата, изяла му воловете и поискала и него да изяде, та му рекла — иди в дола да се умиеш на рекичката, че ще те изям! човекът се уплашил. нямало как да се спаси и отишъл в дола да се мие. вървял и плачел. насреща му изскочил заекът и запитал — защо плачеш, чичо? — ех, чичовото, не питай, миличко! голяма беда ми дойде на главата. мечката изяде воловете ми, сега иска и мен да яде, че ме проводи да се измия, та чист да ме изяде. заекът рекъл — не бой се, чичко, аз ще те спася! иди ми намери две ръжени сламки за пищов, донеси ми и елхови кори за пушка. аз ще отида хей на оня баир отсреща, ще ти извикам за лов, и ти, както ти дойде по-добре, тъй стори. човекът рекъл — хей, зайко, това е празна работа. можеш ли ти да\n",
      "\n",
      "---\n",
      "\n",
      "една вечер, тъкмо се канеше да ходи в нивите на паша, нещо зашумоля край него. заекът се надигна и опули очи. гледа — по земята се влачи нещо — нито корен, нито мъхната шапка. заекът се изплаши, то се знае, но потрая още минутка да разбере какво пълзи. и видя таралежа. таралежът току-що беше напуснал плитката си дупка. листата, които беше накичил по бодлите си още през есента, тъй си стояха по него. — отърси се, не приличаш на нищо — каза заекът. таралежът повдигна глава и черните му очи сърдито блеснаха под товара от гнила шума и дребни съчки. — гледай си работата, от тебе не ща ум! — мрачно отвърна той. таралежът много разчиташе на външния си вид да хване тая нощ някоя мишка. като легнеше край мишата дупка, щеше да остане невидим. през деня той не смееше да се показва из гората. гората\n",
      "\n",
      "---\n",
      "\n",
      "крадливият заек: още открай време човекът избрал кучето за другар. то било най-вярното животно, което пазело човека от лоши зверове. затова човекът водел кучето навсякъде със себе си и за да не го болят краката, направил му цървули. веднъж, било през лятото, цървулите на кучето били много стегнати, та то седнало край една рекичка, събуло ги и ги потопило във водата, да се разпуснат. докато си почивало така на сянка, кучето позадрямало. а заекът минал покрай него и видял цървулите във водата. погледал ги, почудил се, па току се навел, та ги грабнал, обул ги и взел да се изпъва, да се оглежда, да стъпва гордо. не могъл да се нарадва зайо на хубавите цървули. през това време кучето се събудило и под око наблюдавало зайчето какво ще направи с цървулите. зайко подскачал радостно, подскачал и\n",
      "\n",
      "---\n",
      "\n",
      "да стъпва гордо. не могъл да се нарадва зайо на хубавите цървули. през това време кучето се събудило и под око наблюдавало зайчето какво ще направи с цървулите. зайко подскачал радостно, подскачал и взел да се отдалечава от кучето. тогава кучето скочило и подгонило заека, за да си вземе цървулите. дотогава никога кучето не преследвало зайци. а заекът харесал цървулите, решил да не ги връща на кучето и беж да го няма. оттогава, та и до днес кучето гони заека, за да си вземе цървулите. когато се случи да хване заек, кучето не може да си вземе цървулите, защото те са зараснали за заешките крака. но то гони зайците, защото усеща миризмата на своите цървули, и се ядосва на заека, че е откраднал най-удобните му обувки. а горкият заек много пъти се разкайвал за кражбата, която някога направил,\n",
      "\n",
      "---\n",
      "\n",
      "заекът ходил из полето да събира лековити билки, да вари лек за лъва. той бил стигнал до къщата на лъва точно когато баба меца влязла. и от срам и страх заекът останал пред вратата, та чул какво попитал лъвът, какво отговорила баба меца, как след това лъвът я разкъсал и изял. постоял пред вратата, помислил, па след това се престрашил и влязъл — добър ден, лъвчо! донесох ти лековити билки — рекъл бързо той. — къде да ги сваря, та да дам да ги пиеш? трябва скоро да оздравееш, защото ние не можем да живеем без цар. — билките ще свариш, зайчо — рекъл лъвът, — ама я ми кажи, като влизаш в моята къща, мирише ли, или вони? — мирише, лъвчо, мирише на хубаво, като в моминска градина! — ех, зайчо, зная си аз, че ти си добър приятел — рекъл лъвът. — ела, пооправи възглавницата под главата ми, че\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: разкажи дълга приказка за заек?\n",
      "\n",
      "Answer allways in full sentences.\n",
      "Answer allways in Bulgarian.\n",
      "Reformat the result to be more readable.\n",
      "Reformat the to exclude repetitions of words.\n",
      "Приказката трябва да бъде дълга и интересна.\n",
      "Приказката трябва да има пучаващ край.\n",
      "Приказката не трябва да бъде със съдържание, което не е подходящо за деца.\n",
      "Приказката трябва да бъде със съдържание, което е подходящо за деца.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Langchain dependencies\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader  # Importing PDF loader from Langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Importing text splitter from Langchain\n",
    "from langchain_openai import OpenAIEmbeddings # Importing OpenAI embeddings from Langchain\n",
    "from langchain.schema import Document  # Importing Document schema from Langchain\n",
    "from langchain_chroma import Chroma  # Importing Chroma vector store from Langchain\n",
    "from dotenv import load_dotenv # Importing dotenv to get API key from .env file\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import os  # Importing os module for operating system functionalities\n",
    "import shutil  # Importing shutil module for high-level file operations\n",
    "import os\n",
    "import json\n",
    "\n",
    "CHROMA_PATH = \"../Base_Embeded/Basic_chroma\"  # Path to store the vector store\n",
    "\n",
    "import os\n",
    "import json\n",
    "def load_api_key_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "    return config['OPENAI_API_KEY']\n",
    "\n",
    "# Load the API key from the JSON file\n",
    "api_key = load_api_key_from_json('../config.json')\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "# Use same embedding function as before\n",
    "embedding_function = OpenAIEmbeddings(\n",
    "    model = 'text-embedding-3-small',\n",
    "    )\n",
    " \n",
    "# Prepare the database\n",
    "db1 = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "#db2 = Chroma(persist_directory='full_books_2', embedding_function=embedding_function)\n",
    "\n",
    "#db2_data=db2._collection.get(include=['documents','metadatas','embeddings'])\n",
    "#db1._collection.add(\n",
    "#     embeddings=db2_data['embeddings'],\n",
    "#     metadatas=db2_data['metadatas'],\n",
    "#     documents=db2_data['documents'],\n",
    "#     ids=db2_data['ids']\n",
    "#)\n",
    "\n",
    "\n",
    "# install package\n",
    "#%pip install -U langchain-ollama\n",
    "#https://python.langchain.com/docs/integrations/llms/ollama/\n",
    "\n",
    "# Set up the local model\n",
    "#model = OllamaLLM(model=\"todorov/bggpt:latest\")\n",
    "\n",
    "\n",
    "# Set up the Open AI model\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # Use a smaller model for faster response times\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.7,  # Increase temperature for more creativity\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\n",
    "Answer allways in full sentences.\n",
    "Answer allways in Bulgarian.\n",
    "Reformat the result to be more readable.\n",
    "Reformat the to exclude repetitions of words.\n",
    "Приказката трябва да бъде дълга и интересна.\n",
    "Приказката трябва да има пучаващ край.\n",
    "Приказката не трябва да бъде със съдържание, което не е подходящо за деца.\n",
    "Приказката трябва да бъде със съдържание, което е подходящо за деца.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_text = \"разкажи дълга приказка за заек?\"\n",
    "\n",
    "# Search the DB.\n",
    "results = db1.similarity_search_with_relevance_scores(query_text, k=5)\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "    return config['OPENAI_API_KEY']\n",
    "\n",
    "# Load the API key from the JSON file\n",
    "api_key = load_api_key_from_json('config.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
