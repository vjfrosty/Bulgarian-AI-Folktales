{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\a1bg532573\\repo\\Bulgarian-AI-Folktales\\preprocesing')\n",
    "# imports \n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader  # Importing PDF loader from Langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Importing text splitter from Langchain\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings # Importing OpenAI embeddings from Langchain\n",
    "from langchain.schema import Document  # Importing Document schema from Langchain\n",
    "from langchain_chroma import Chroma  # Importing Chroma vector store from Langchain\n",
    "from dotenv import load_dotenv # Importing dotenv to get API key from .env file\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "import os  # Importing os module for operating system functionalities\n",
    "import shutil  # Importing shutil module for high-level file operations\n",
    "\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load documents and clean duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(DATA_PATH):\n",
    "    \"\"\"\n",
    "    Load text documents from JSON files in the specified directory.\n",
    "\n",
    "    Returns:\n",
    "        List of Document objects: Loaded text documents represented as Langchain Document objects.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for filename in os.listdir(DATA_PATH):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(DATA_PATH, filename)\n",
    "            \n",
    "            # Open and read each JSON file\n",
    "            with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                \n",
    "                # Extract book, author, and stories from JSON\n",
    "                book_name = data.get(\"book\", \"\")\n",
    "                author = data.get(\"author\", \"\")\n",
    "                stories = data.get(\"stories\", [])\n",
    "\n",
    "                # Iterate through each story and create Document objects\n",
    "                for story in stories:\n",
    "                    if \"story\" in story or \"author\" in story:\n",
    "                        story_title = story.get(\"story\") or story.get(\"author\")\n",
    "                        story_content = story.get(\"content\", \"\")\n",
    "\n",
    "                        # Append the story title to the beginning of the story content\n",
    "                        combined_content = f\"{story_title}: {story_content}\"\n",
    "\n",
    "                        # Create a Document object with metadata\n",
    "                        document = Document(\n",
    "                            page_content=combined_content,\n",
    "                            metadata={\n",
    "                                \"book\": book_name,\n",
    "                                \"author\": author,\n",
    "                                \"story\": story_title\n",
    "                            }\n",
    "                        )\n",
    "                        # Append the document to the list of documents\n",
    "                        documents.append(document)\n",
    "\n",
    "    return documents\n",
    "\n",
    "def keep_unique_documents(documents):\n",
    "    \"\"\"\n",
    "    Keep only one unique record for each duplicate, removing redundant records.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of Document objects.\n",
    "\n",
    "    Returns:\n",
    "        List of Document objects: List with unique documents, retaining one instance for each duplicate.\n",
    "    \"\"\"\n",
    "    content_tracker = {}\n",
    "    unique_documents = []\n",
    "\n",
    "    # Track each document's combined content and keep only the first occurrence\n",
    "    for doc in documents:\n",
    "        content = doc.page_content.strip().lower()  # Normalize for comparison\n",
    "        if content not in content_tracker:\n",
    "            # Add the first occurrence to the unique list\n",
    "            content_tracker[content] = doc\n",
    "            unique_documents.append(doc)\n",
    "\n",
    "    return unique_documents\n",
    "\n",
    "DATA_PATH = 'output_json_files'\n",
    "documents = load_documents(DATA_PATH)  # Load documents from a source\n",
    "unique_documents = keep_unique_documents(documents)  # Keep only unique documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building a small quick token size function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(text: str, model: str = \"gpt-3.5-turbo\") -> int:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a given text using the specified model's tokenizer.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to tokenize.\n",
    "        model (str): The name of the model to use for tokenization (default: \"gpt-3.5-turbo\").\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens in the text.\n",
    "    \"\"\"\n",
    "    model = \"gpt-4o-mini\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sort documents by token size and print first and last examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: повест за една гора... | Tokens: 75356\n",
      "Document: срещата на най-големия с ламят... | Tokens: 18720\n",
      "Document: щетинското ханче... | Tokens: 10889\n",
      "Document: в тронната зала... | Tokens: 8410\n",
      "Document: веселият монах... | Tokens: 7511\n",
      "Document: босата команда... | Tokens: 6840\n",
      "Document: гарван грачи... | Tokens: 5535\n",
      "Document: юнакът със звезда на челото и ... | Tokens: 5135\n",
      "Document: юнакът със звезда на челото и ... | Tokens: 5129\n",
      "Document: врабчетата на стрина дойна... | Tokens: 4829\n",
      "---------------\n",
      "Document: жените или мъжете са повече на земята?: където ходели настрадин ходжа и хитър петър, все се нещо препирали, изпитвали, надлъгвали. като вървели веднъж. хитър петър разправял, че жените са повече на земното кълбо, а ходжата казвал, че мъжете са повече. слушал го, слушал хитър петър, па му рекъл — не си прав, ходжа! жените са повече, защото има мъже, които слушат жените си затова и те се числят към жените!... | Tokens: 141\n",
      "Document: изгубил доверие: в селото на хитър петър дошел другоселец да си купува вол. хитър петър го водел от къща на къща да изберат млад и хубав вол. като вървели из улицата хитър петър рекъл на другоселеца — байо, дай ми сто гроша назаем! — ами аз те не познавам! — рекъл му другоселецът. — та аз тъкмо затова искам от тебе — рекъл хитър петър, — че ония, които ме познават, не ми дават... | Tokens: 140\n",
      "Document: колко са завоите в целия свят: едни шегобийци срещнали хитър петър и като искали да се подиграят с него, рекли — хайде, петре, като си толкова хитър, можеш ли ни каза — колко завои има из целия свят? хитър петър отговорил на часа — от това по-лесно няма! завоите са само два — ляв и десен! шегобийците останали с пръст в устата, че не могли и тоя път да надхитрят хитър петър.... | Tokens: 134\n",
      "Document: залъкът на богаташа: един богаташин се карал нещо на сиромасите и почнал да им вика — аз съм си купил голям имот, ама съм си отделял от залъка! а вие всичко изяждате, затова сте фукари! зачул го хитър петър и му казва — ега ти залъкът! какъв ли ще е тоя толкоз голям залък, та да спечелиш такова голямо богатство и да купиш такъв имот!... | Tokens: 125\n",
      "Document: срещу нова година: спи, моя палава сестричке, спят зайчета, щурци и птички. след малко тихо през комина ще дойде новата година. и кой каквото си сънува наяве тя ще му дарува на катеричката — бадеми, на зайо — моркови големи, на тебе — кукла за другарче, на мене — шарено букварче. спи, някой идва през комина. дали е новата година?... | Tokens: 124\n",
      "Document: книжки мои: писмо тихо затваряйте в къщи вратите! тихо пристъпвайте — да не шумите! катето нека остане само, катето пише днес първо писмо. катето всяка стотинка пестило, та да си купи и плик, и мастило, та да напише с трептяща ръчичка бабо, и аз съм сега ученичка. скоро голямо писмо ще ти пратя. поздрав от всички. целува те катя.... | Tokens: 123\n",
      "Document: млекари: дълго време хитър петър и разумни радой продавали мляко. радой виждал, че хитър петър продавал много повече мляко от него, та веднъж го запитал — петре, ти колко крави доиш? — две крави. — и колко мляко надояваш от тях? — надоявам пет-шест кила. — а колко продаваш всеки ден? — както се случи понякога петнайсет, понякога двайсет... | Tokens: 122\n",
      "Document: хитрият гайдарджия: синът на хитър петър се учел да свири на гайда. баща му, за да го насърчи да свири, му рекъл — сине, като свириш от сутрин до вечер, ще ти давам всеки ден по едно петаче! а малкият хитрец отговорил — нямам сметка, тате, защото съседите ми дават по грош на ден, за да не свиря.... | Tokens: 109\n",
      "Document: тънка сметка: хитър петър го съдили. кадията му казал — осъждам те на двайсет и пет дена затвор! — мога ли, кади ефенди, да ги излежа през зимата? — попитал хитър петър. — защо пък искаш през зимата? — запитал го кадията. — защото тогава дните са по-къси — отговорил хитър петър.... | Tokens: 105\n",
      "Document: защо е несресан волът?: веднъж хитър петър карал два вола из улицата. срещнали го някои шегаджии и го запитали — петре, защо ти е единият вол рошав? ти не си го гледал добре! хитър петър отговорил — тоя вол не се е бръснал, че е умрял баща му. затова ходи рошав.... | Tokens: 101\n",
      "Document: нощ: темно, брате, темно, ете, като в катраница, нито месечинка свети, ни ясна звездица! куче лае у полето, та си глава кине — ергени ли мома краднат, или некой гине? та нема ли кой да палне плевнико на кмето да разпусне това пусто темнило проклето!... | Tokens: 96\n",
      "Document: как големците излизат на пазар: един ден по тържището минавал някой си големец, а подир него вървял неговият слуга. като го съгледал хитър петър казал на хората — тоя човек се е научил да ходи като магарето, което не върви, додето не го карат отподире му... | Tokens: 87\n",
      "Document: на мама: задето песни си ми пяла, край мене ден и нощ си бдяла и ме научи да се трудя и рано-рано да се будя, а в нашата родина свята да пазя вярно свободата — три думи ще ти кажа само — благодаря, обична мамо!... | Tokens: 72\n",
      "Document: ран босилек: неродена мома. незнаен юнак. жива вода неродена мома. незнаен юнак. жива вода - народни приказки неродена мома. незнаен юнак. жива вода - народни приказки ран босилек... | Tokens: 64\n",
      "Document: елин пелин: съчинения в шест тома — том пети елин пелин съчинения в шест тома — том пети... | Tokens: 33\n",
      "Document: леда милева: в една зоологическа градина леда милева в една зоологическа градина леда милева... | Tokens: 31\n",
      "Document: елин пелин: сватбата на червенушко елин пелин весела приказка в стихове... | Tokens: 27\n",
      "Document: сава попов: хитър петър народни приказки - хитър петър хумор сава попов... | Tokens: 25\n",
      "Document: горска хубавица: народни приказки горска хубавица народни приказки народни приказки... | Tokens: 23\n",
      "Document: ангел каралийчев: български народни приказки - том 2... | Tokens: 18\n",
      "Document: ангел каралийчев: български народни приказки том 1... | Tokens: 17\n",
      "Document: ангел каралийчев: имало едно време - народни приказки... | Tokens: 17\n",
      "Document: ангел каралийчев: тошко африкански и приказки... | Tokens: 17\n",
      "Document: ангел каралийчев: български народни приказки ак2... | Tokens: 16\n",
      "Document: ангел каралийчев: лъв без опашка... | Tokens: 13\n",
      "Document: ангел каралийчев: приказки и разкази... | Tokens: 13\n",
      "Document: през планини и морета: момчето без име... | Tokens: 13\n",
      "Document: елин пелин: пижо и пендо... | Tokens: 12\n",
      "Document: елин пелин: повести и разкази... | Tokens: 12\n",
      "Document: елин пелин: гори тилилейски... | Tokens: 11\n"
     ]
    }
   ],
   "source": [
    "# sort unique_documents by unique_documents[i].page_content token size\n",
    "sorted_documents = sorted(unique_documents, key=lambda x: count_tokens(x.page_content), reverse=True)\n",
    "\n",
    "# Print the first 10 documents\n",
    "for doc in sorted_documents[:10]:\n",
    "    print(f\"Document: {doc.metadata['story'][:30]}... | Tokens: {count_tokens(doc.page_content)}\")\n",
    "print(\"---------------\")\n",
    "# Print last 10 documents\n",
    "for doc in sorted_documents[-30:]:\n",
    "    print(f\"Document: {doc.page_content}... | Tokens: {count_tokens(doc.page_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sort docments in bins based on token counts\n",
    "#### 1. Dropping binned_documents['0-60'] as it is too small and possible left noise from parsing\n",
    "#### 2. Taking bin ['60-1000'] as full ebedding\n",
    "#### 3. Taking bin ['1000-'float('inf')] as chunk embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin 0-60: 16 documents\n",
      "Bin 60-1000: 398 documents\n",
      "Bin 1000-inf: 433 documents\n",
      "\n",
      "Bin 0-60:\n",
      "  Document: елин пелин... | Tokens: 33\n",
      "  Document: леда милева... | Tokens: 31\n",
      "  Document: елин пелин... | Tokens: 27\n",
      "  Document: сава попов... | Tokens: 25\n",
      "  Document: горска хубавица... | Tokens: 23\n",
      "  Document: ангел каралийчев... | Tokens: 18\n",
      "  Document: ангел каралийчев... | Tokens: 17\n",
      "  Document: ангел каралийчев... | Tokens: 17\n",
      "  Document: ангел каралийчев... | Tokens: 17\n",
      "  Document: ангел каралийчев... | Tokens: 16\n",
      "  Document: ангел каралийчев... | Tokens: 13\n",
      "  Document: ангел каралийчев... | Tokens: 13\n",
      "  Document: през планини и морета... | Tokens: 13\n",
      "  Document: елин пелин... | Tokens: 12\n",
      "  Document: елин пелин... | Tokens: 12\n",
      "  Document: елин пелин... | Tokens: 11\n",
      "  Last 20 documents in 0-60:\n",
      "    Document: елин пелин... | Tokens: 33\n",
      "    Document: леда милева... | Tokens: 31\n",
      "    Document: елин пелин... | Tokens: 27\n",
      "    Document: сава попов... | Tokens: 25\n",
      "    Document: горска хубавица... | Tokens: 23\n",
      "    Document: ангел каралийчев... | Tokens: 18\n",
      "    Document: ангел каралийчев... | Tokens: 17\n",
      "    Document: ангел каралийчев... | Tokens: 17\n",
      "    Document: ангел каралийчев... | Tokens: 17\n",
      "    Document: ангел каралийчев... | Tokens: 16\n",
      "    Document: ангел каралийчев... | Tokens: 13\n",
      "    Document: ангел каралийчев... | Tokens: 13\n",
      "    Document: през планини и морета... | Tokens: 13\n",
      "    Document: елин пелин... | Tokens: 12\n",
      "    Document: елин пелин... | Tokens: 12\n",
      "    Document: елин пелин... | Tokens: 11\n",
      "\n",
      "Bin 60-1000:\n",
      "  Document: трите патенца... | Tokens: 999\n",
      "  Document: сън... | Tokens: 993\n",
      "  Document: клан-недоклан... | Tokens: 978\n",
      "  Document: как хитър петър засрамил своя ... | Tokens: 975\n",
      "  Document: хитър петър лъже, настрадин хо... | Tokens: 963\n",
      "  Document: оскубаната гъска... | Tokens: 955\n",
      "  Document: приказка за патката и пушката... | Tokens: 952\n",
      "  Document: косе босе... | Tokens: 942\n",
      "  Document: наддумване... | Tokens: 942\n",
      "  Document: магарето на сюлейман ага... | Tokens: 939\n",
      "  Document: излъганите лъжци... | Tokens: 936\n",
      "  Document: гнездо в гнездо... | Tokens: 934\n",
      "  Document: подплашените вълци... | Tokens: 932\n",
      "  Document: мечтите на едно момче... | Tokens: 929\n",
      "  Document: цар цървулан... | Tokens: 926\n",
      "  Document: чисто носи — сладко яде... | Tokens: 926\n",
      "  Document: котето и лъвът... | Tokens: 925\n",
      "  Document: вълк и козел... | Tokens: 924\n",
      "  Document: ученикът надминал учителя си... | Tokens: 921\n",
      "  Document: хитър петър оправя турското ца... | Tokens: 914\n",
      "  ...\n",
      "  Last 20 documents in 60-1000:\n",
      "    Document: иван жеглов... | Tokens: 152\n",
      "    Document: случка... | Tokens: 151\n",
      "    Document: като виждаш, не питай!... | Tokens: 146\n",
      "    Document: свири на цигулка... | Tokens: 144\n",
      "    Document: десет гроша... | Tokens: 143\n",
      "    Document: не е хигиенично... | Tokens: 142\n",
      "    Document: жените или мъжете са повече на... | Tokens: 141\n",
      "    Document: изгубил доверие... | Tokens: 140\n",
      "    Document: колко са завоите в целия свят... | Tokens: 134\n",
      "    Document: залъкът на богаташа... | Tokens: 125\n",
      "    Document: срещу нова година... | Tokens: 124\n",
      "    Document: книжки мои... | Tokens: 123\n",
      "    Document: млекари... | Tokens: 122\n",
      "    Document: хитрият гайдарджия... | Tokens: 109\n",
      "    Document: тънка сметка... | Tokens: 105\n",
      "    Document: защо е несресан волът?... | Tokens: 101\n",
      "    Document: нощ... | Tokens: 96\n",
      "    Document: как големците излизат на пазар... | Tokens: 87\n",
      "    Document: на мама... | Tokens: 72\n",
      "    Document: ран босилек... | Tokens: 64\n",
      "\n",
      "Bin 1000-inf:\n",
      "  Document: повест за една гора... | Tokens: 75356\n",
      "  Document: срещата на най-големия с ламят... | Tokens: 18720\n",
      "  Document: щетинското ханче... | Tokens: 10889\n",
      "  Document: в тронната зала... | Tokens: 8410\n",
      "  Document: веселият монах... | Tokens: 7511\n",
      "  Document: босата команда... | Tokens: 6840\n",
      "  Document: гарван грачи... | Tokens: 5535\n",
      "  Document: юнакът със звезда на челото и ... | Tokens: 5135\n",
      "  Document: юнакът със звезда на челото и ... | Tokens: 5129\n",
      "  Document: врабчетата на стрина дойна... | Tokens: 4829\n",
      "  Document: в изгнание... | Tokens: 4780\n",
      "  Document: най-хубавата земя... | Tokens: 4680\n",
      "  Document: колко народ се беше насъбрал д... | Tokens: 4621\n",
      "  Document: братче и сестриче... | Tokens: 4344\n",
      "  Document: сиромашка правда... | Tokens: 4310\n",
      "  Document: момчето, кученцето, котенцето ... | Tokens: 4286\n",
      "  Document: хитрецът и царската дъщеря... | Tokens: 4217\n",
      "  Document: отец герасим... | Tokens: 4154\n",
      "  Document: симовци... | Tokens: 4131\n",
      "  Document: бялото гълъбче... | Tokens: 4079\n",
      "  ...\n",
      "  Last 20 documents in 1000-inf:\n",
      "    Document: хитър петър надхитря настрадин... | Tokens: 1105\n",
      "    Document: по следите на ламята... | Tokens: 1104\n",
      "    Document: мечката и мравките... | Tokens: 1095\n",
      "    Document: лъв и човек... | Tokens: 1085\n",
      "    Document: котаран... | Tokens: 1083\n",
      "    Document: хитрините на кума-лиса... | Tokens: 1078\n",
      "    Document: умна девойка... | Tokens: 1072\n",
      "    Document: старият елен и малкото еленче... | Tokens: 1068\n",
      "    Document: как се запознали хитър петър и... | Tokens: 1067\n",
      "    Document: човекът и лъвът... | Tokens: 1064\n",
      "    Document: ослепената кокошка... | Tokens: 1059\n",
      "    Document: лъв и човек... | Tokens: 1059\n",
      "    Document: гостолюбивите мравки... | Tokens: 1057\n",
      "    Document: гудо и агудо... | Tokens: 1055\n",
      "    Document: как хитър петър получил името ... | Tokens: 1046\n",
      "    Document: вълкът си е вълк... | Tokens: 1041\n",
      "    Document: дядовата ръкавичка... | Tokens: 1036\n",
      "    Document: кон и лисица... | Tokens: 1028\n",
      "    Document: умни хора... | Tokens: 1016\n",
      "    Document: врабчето си иска зърното... | Tokens: 1009\n"
     ]
    }
   ],
   "source": [
    "def sort_documents_into_bins(documents, bin_ranges):\n",
    "    \"\"\"\n",
    "    Sort documents into bins based on their token counts.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of Document objects.\n",
    "        bin_ranges (list): List of tuples representing the start and end of each bin range.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with bin ranges as keys and sorted lists of documents as values.\n",
    "    \"\"\"\n",
    "    bins = {f\"{start}-{end}\": [] for start, end in bin_ranges}\n",
    "    \n",
    "    for doc in documents:\n",
    "        token_count = count_tokens(doc.page_content)\n",
    "        for start, end in bin_ranges:\n",
    "            if start <= token_count < end:\n",
    "                bins[f\"{start}-{end}\"].append((doc, token_count))\n",
    "                break\n",
    "    \n",
    "    # Sort documents within each bin by token count (descending order)\n",
    "    for bin_range in bins:\n",
    "        bins[bin_range].sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return bins\n",
    "\n",
    "# Define bin ranges\n",
    "bin_ranges = [(0, 60), (60, 1000), (1000, float('inf'))]\n",
    "\n",
    "# Sort documents into bins\n",
    "binned_documents = sort_documents_into_bins(unique_documents, bin_ranges)\n",
    "\n",
    "# Print the number of documents in each bin\n",
    "for bin_range, docs in binned_documents.items():\n",
    "    print(f\"Bin {bin_range}: {len(docs)} documents\")\n",
    "\n",
    "# Print example documents from each bin\n",
    "for bin_range, docs in binned_documents.items():\n",
    "    print(f\"\\nBin {bin_range}:\")\n",
    "    for doc, token_count in docs[:20]:  # Print first 20 documents in each bin\n",
    "        print(f\"  Document: {doc.metadata['story'][:30]}... | Tokens: {token_count}\")\n",
    "    if len(docs) > 20:\n",
    "        print(\"  ...\")\n",
    "    # Print last 20 documents in each bin\n",
    "    print(f\"  Last 20 documents in {bin_range}:\")\n",
    "    for doc, token_count in docs[-20:]:\n",
    "        print(f\"    Document: {doc.metadata['story'][:30]}... | Tokens: {token_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Custom Contextual Enhancing embedding for ['60-1000'] bin (**Small Stories**) and ['1000-inf'] bin (**Large Stories**) with GPT-4o-mini\n",
    "\n",
    "- Timeout mechanism to avoid hitting TPM limit of gpt-4o-mini (200 000 TPM) - keep track of the number of tokens sent to the LLM and pause for 1 minute the process if the limit is about to be reached\n",
    "- Handling large documents:\n",
    "1. Document size: Handles texts ranging from 1,000 to 20,000 tokens.\n",
    "2. Dynamic chunking: Uses a text splitter to divide documents into ~1,000 token chunks with 200 token overlap. Chunk count adapts to document length.\n",
    "3. Contextual embedding: Applies `get_contextual_embedding()` with `prompt_type=\"contextual\"` to each chunk, providing context within the full document.\n",
    "4. Document-level enhancement: Calls `get_contextual_embedding()` with `prompt_type=\"enhancing\"` once for the entire document.\n",
    "5. Information combination: Appends both chunk-specific contextual info and document-level enhancing info to each chunk, resulting in multiple chunks with shared enhancing info but unique contextual details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 1/3: трите патенца...\n",
      "Embedded small document: трите патенца...\n",
      "Total tokens: 999\n",
      "Processing document 2/3: сън...\n",
      "Embedded small document: сън...\n",
      "Total tokens: 1992\n",
      "Processing document 3/3: врабчето си иска зърното...\n",
      "Embedded large document: врабчето си иска зърното...\n",
      "Number of splits: 2 for Character count: 2523 for Tokens 1009\n",
      "Total tokens: 3001\n",
      "Saved 4 documents to vector_store_test.\n",
      "Finished embedding all documents and saved to Chroma DB.\n",
      "Document IDs:\n",
      "['b51a5ca9-5852-47dc-8a76-518726a93bc1', '87a8cc1b-58d6-4146-a101-a59db6e670ed', '0f97b8f7-7fb5-4eb4-a809-5922889cdd8c', '1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "TEST_CHROMA_PATH = \"vector_store_test\"\n",
    "TPM_LIMIT = 200000\n",
    "PAUSE_TIME = 80  # seconds\n",
    "\n",
    "with open('../config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize components\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# Set up ChatOpenAI model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # Use a smaller model for faster response times\n",
    "    # model=\"gpt-4o\",  # Use a smaller model for faster response times\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0,       # Increase temperature for more creativity\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "def translate_in_bulgarian(text, llm=None):\n",
    "\n",
    "    if llm is not None:\n",
    "        transation_prompt =f\"\"\"Translate the following text into Bulgarian. Please adhere to these guidelines:\n",
    "\n",
    "        1. Maintain the original meaning and tone.\n",
    "        2. Avoid word-for-word translation; focus on natural Bulgarian phrasing.\n",
    "        3. Use diverse vocabulary to prevent repetition of words or phrases.\n",
    "        4. Preserve any formatting or structure present in the original text.\n",
    "        5. If there are specialized terms, provide the most appropriate Bulgarian equivalent.\n",
    "        6. Ensure the translation aligns with Bulgarian cultural context where applicable.\n",
    "\n",
    "        <text>\n",
    "        {text}\n",
    "        </text>\n",
    "\n",
    "        Please provide only the Bulgarian translation without any additional comments.\"\"\"\n",
    "\n",
    "        response = llm.invoke(transation_prompt)\n",
    "        response = response.content\n",
    "    else:\n",
    "        # use DeepL \n",
    "        deepl_auth_key = \"3afd0c9a-0aa4-9220-6227-778e77bcfc64:fx\"  # Replace with your key\n",
    "        translator = deepl.Translator(deepl_auth_key)\n",
    "\n",
    "        result = translator.translate_text(text, target_lang=\"BG\")\n",
    "        response = result.text\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_contextual_embedding(doc: Document, llm: ChatOpenAI, prompt_type: str, full_text: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Generate a contextual embedding for a document using the LLM.\n",
    "    \n",
    "    Args:\n",
    "        doc (Document): The document or chunk to embed.\n",
    "        llm (ChatOpenAI): The language model to use for generating context.\n",
    "        prompt_type (str): Type of prompt to use (\"contextual\" or \"enhancing\").\n",
    "        full_text (str): The full text of the document (used for contextual embedding).\n",
    "    \n",
    "    Returns:\n",
    "        str: The contextual embedding as a string.\n",
    "    \"\"\"\n",
    "    if prompt_type == \"contextual\":\n",
    "        prompt = f\"\"\"\n",
    "        Here is the chunk we want to situate within the whole document\n",
    "        <chunk>\n",
    "        {doc.page_content}\n",
    "        </chunk>\n",
    "\n",
    "        Here is the content of the whole document\n",
    "        <document>\n",
    "        {full_text}\n",
    "        </document>\n",
    "\n",
    "        Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk.\n",
    "        Answer only with the succinct context and nothing else. Answer in Bulgarian.\n",
    "        \"\"\"\n",
    "    elif prompt_type == \"enhancing\":\n",
    "        prompt = f\"\"\"\n",
    "        Based on the following story, provide a concise summary including:\n",
    "        1. A brief synopsis of the story\n",
    "        2. The main characters\n",
    "        3. The setting or environment\n",
    "        4. The moral or main message of the story\n",
    "        <story>\n",
    "        Story: {doc.page_content}\n",
    "        </story>\n",
    "\n",
    "        Respond in a concise paragraph format: \"**brief summary of the story:** ..., **main characters:** ..., **setting:** ..., **moral:** ...\" *... are placeholders for the actual values you will provide after reading the story. Please give a succinct answer to augment the document for the purposes of improving search retrieval of the story.\n",
    "        Separate every value in a separate line with a new line character.\n",
    "        \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def extract_main_characters(enhancing_info):\n",
    "    lines = enhancing_info.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.startswith(\"**главни герои:**\"):\n",
    "            return line.split(\":**\", 1)[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "def embed_documents(documents: List[Tuple[Document, int]], llm: ChatOpenAI, embeddings, chroma_path: str) -> None:\n",
    "    total_tokens = 0\n",
    "    start_time = time.time()\n",
    "    combined_docs = []\n",
    "    doc_id = 1  # Start with document ID 1\n",
    "\n",
    "    for idx, (doc, token_count) in enumerate(documents, 1):\n",
    "        print(f\"Processing document {idx}/{len(documents)}: {doc.metadata['story'][:30]}...\")\n",
    "        \n",
    "        if total_tokens + token_count > TPM_LIMIT:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time < PAUSE_TIME:\n",
    "                pause_duration = PAUSE_TIME - elapsed_time\n",
    "                print(f\"Approaching TPM limit. Pausing for {pause_duration:.2f} seconds.\")\n",
    "                time.sleep(pause_duration)\n",
    "            total_tokens = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "        is_large_doc = token_count >= 1000\n",
    "\n",
    "        if is_large_doc:\n",
    "            character_count = len(doc.page_content)\n",
    "            num_chunks = max(2, token_count // 1000)\n",
    "            chunk_size = (character_count // num_chunks) + 200\n",
    "            \n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=200,\n",
    "                length_function=len,\n",
    "            )\n",
    "\n",
    "            chunks = text_splitter.split_documents([doc])\n",
    "\n",
    "            enhancing_info = get_contextual_embedding(doc, llm, prompt_type=\"enhancing\")\n",
    "            enhancing_info = translate_in_bulgarian(enhancing_info, llm=None) #llm=None use DeepL api\n",
    "            # enhancing_info = translate_in_bulgarian(enhancing_info, llm)\n",
    "            main_characters = extract_main_characters(enhancing_info)\n",
    "            \n",
    "            for chunk_idx, chunk in enumerate(chunks, 1):\n",
    "                contextual_info = get_contextual_embedding(chunk, llm, prompt_type=\"contextual\", full_text=doc.page_content)\n",
    "                combined_content = f\"{chunk.page_content}\\n\\nContextual Information:\\n\\n{contextual_info}\\n\\nEnhancing Information:\\n\\n{enhancing_info}\"\n",
    "                \n",
    "                contextual_doc = Document(page_content=combined_content, metadata={**doc.metadata, 'main_characters': main_characters})\n",
    "\n",
    "                combined_docs.append((str(doc_id), contextual_doc))\n",
    "                doc_id += 1\n",
    "\n",
    "            print(f\"Embedded large document: {doc.metadata['story'][:30]}...\")\n",
    "            print(f\"Number of splits: {len(chunks)} for Character count: {character_count} for Tokens {token_count}\")\n",
    "        else:\n",
    "            enhancing_info = get_contextual_embedding(doc, llm, prompt_type=\"enhancing\")\n",
    "            enhancing_info = translate_in_bulgarian(enhancing_info, llm=None) # llm=None using DeepL\n",
    "            # enhancing_info = translate_in_bulgarian(enhancing_info, llm)\n",
    "            # add main character metadata\n",
    "            main_characters = extract_main_characters(enhancing_info)\n",
    "            combined_content = f\"{doc.page_content}\\n\\nEnhancing Information:\\n\\n{enhancing_info}\"\n",
    "            \n",
    "            contextual_doc = Document(page_content=combined_content, metadata={**doc.metadata, 'main_characters': main_characters})\n",
    "            \n",
    "            combined_docs.append((str(doc_id), contextual_doc))\n",
    "            doc_id += 1\n",
    "            print(f\"Embedded small document: {doc.metadata['story'][:30]}...\")\n",
    "\n",
    "        total_tokens += token_count\n",
    "        print(f\"Total tokens: {total_tokens}\")\n",
    "    \n",
    "    db = Chroma.from_documents(\n",
    "        documents=[doc for _, doc in combined_docs],\n",
    "        embedding=embeddings,\n",
    "        persist_directory=chroma_path,\n",
    "        ids=[id for id, _ in combined_docs]\n",
    "    )\n",
    "    print(f\"Saved {len(combined_docs)} documents to {chroma_path}.\")\n",
    "\n",
    "# Test with documents from both bins\n",
    "small_docs = binned_documents['60-1000'][:2]  # Increased to 2 small documents for better testing\n",
    "large_docs = [binned_documents['1000-inf'][-1]]\n",
    "test_docs = small_docs + large_docs\n",
    "\n",
    "embed_documents(test_docs, llm, embeddings, TEST_CHROMA_PATH)\n",
    "print(\"Finished embedding all documents and saved to Chroma DB.\")\n",
    "\n",
    "# Verify the IDs\n",
    "db = Chroma(persist_directory=TEST_CHROMA_PATH, embedding_function=embeddings)\n",
    "result = db.get(include=['metadatas'])\n",
    "print(\"Document IDs:\")\n",
    "print(result['ids'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Testing the retrieval of the stored embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['b51a5ca9-5852-47dc-8a76-518726a93bc1',\n",
       "  '87a8cc1b-58d6-4146-a101-a59db6e670ed',\n",
       "  '0f97b8f7-7fb5-4eb4-a809-5922889cdd8c',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4'],\n",
       " 'embeddings': array([[ 0.06076654,  0.02530093,  0.01129333, ...,  0.0064741 ,\n",
       "         -0.01222809,  0.03312524],\n",
       "        [ 0.03261885,  0.0120194 , -0.03974689, ...,  0.00992206,\n",
       "          0.02024011,  0.04889894],\n",
       "        [ 0.01968575,  0.01906617, -0.04697545, ...,  0.02292447,\n",
       "          0.00985696,  0.05542427],\n",
       "        ...,\n",
       "        [-0.01562168,  0.02581631, -0.04501637, ...,  0.00038412,\n",
       "          0.0213298 , -0.04110285],\n",
       "        [ 0.02068438,  0.04800818, -0.05613336, ...,  0.02189154,\n",
       "         -0.00986048,  0.04605814],\n",
       "        [ 0.01803932,  0.05230949, -0.06094486, ...,  0.03790969,\n",
       "         -0.01234269,  0.05560992]]),\n",
       " 'metadatas': None,\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['embeddings']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Chroma(persist_directory=TEST_CHROMA_PATH)\n",
    "result = db.get(include=['embeddings'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['4'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'author': 'ангел каралийчев',\n",
       "   'book': 'Български народни приказки ак',\n",
       "   'chunk': 2,\n",
       "   'main_characters': 'Сивото врабче, оградата, огънят, реката, биволът, вълкът, пастирът, мишките и котката.',\n",
       "   'story': 'врабчето си иска зърното',\n",
       "   'total_chunks': 2}],\n",
       " 'documents': ['бивола. — какво приказваш — отговорил вълкът, — додето има такива крехки агънца, що ми трябва жилаво биволско месо! — ще кажа на овчаря да насъска кучетата и те ще ти разкъсат кожуха! — кажи му де! — обърнал се вълкът. — овчарко — викнало отдалече врабчето, — проводи кучетата да изядат вълка! — дордето имам в торбата си мек хляб, защо ми трябва да провождам кучетата да си трошат зъбите с кораво вълче месо — отговорил овчарят. — но аз ще кажа на мишките да ти изгризат торбата! — кажи им де! — мишки — надникнало врабчето в една миша дупка, — излезте да изгризете кожената торба на овчаря! — додето си имаме зърно в житницата, торба няма да гризем — отговорили мишките. тогава врабчето заплакало. видяла го една котка и го попитала — защо плачеш, врабченце? я млъкни! недей натъжава котешкото ми сърце. — ще млъкна, ако изядеш мишките. изведнъж котката се хвърлила върху мишките, мишките — върху торбата на овчаря, овчарят насъскал кучетата си подир вълка, вълкът подгонил бивола, биволът се навел да изпие реката, реката потекла към огъня, огънят запалил единия край на трънения плет, плетът се уплашил и за да не изгори, намерил мънистеното зърно и го дал на врабчето. врабчето се зарадвало много, кацнало на едно клонче, весело зачуруликало и всички се укротили.\\n\\nContextual Information:\\n\\nТози фрагмент представлява част от историята за врабчето, което търси своето изгубено мънистено зърно. В него се описва как врабчето взаимодейства с различни животни, включително вълка, овчаря и бивола, в опит да възстанови зърното си, като всяко животно предлага свои собствени аргументи и заплахи. Краят на фрагмента показва как врабчето, след множество перипетии, най-накрая получава зърното си и се радва.\\n\\nEnhancing Information:\\n\\n**кратко резюме на историята:** Едно сиво врабче губи мънисто, докато ги нанизва на оградата, и си го иска обратно, заплашвайки различни природни стихии. Всяко същество отказва да се съобрази със заплахите на врабчето, докато не се намесва котка, което води до верижна реакция, в резултат на която в крайна сметка врабчето си връща изгубеното мънисто.\\n\\n**главни герои:** Сивото врабче, оградата, огънят, реката, биволът, вълкът, пастирът, мишките и котката.\\n\\n**Място на действието:** Историята се развива в природна среда, в която има ограда, огън, река и гора.\\n\\n**морал:** Историята илюстрира безсмислието на заплахите и взаимосвързаността на природата, като подчертава, че сътрудничеството и разбирането са по-ефективни от сплашването.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "сън: разказва кучето джафко знайте ли кое е на света най-сладко? всички ще речете знаем, джафко, знаем. ти месце обичаш. то за теб ще бъде най-сладкото нещо! — лъжете се, братя! няма да отричам, че месце обичам. но не зная нещо, от съня по-сладко. цял ден си лудувал, джафкал си, играл си. хапнал недохапнал, сръбнал недосръбнал — сгушиш се на топло, па заспиш си сладко. и още по-сладки сънища сънуваш. насън всичко може. ходиш, дето искаш. правиш си на воля, каквото желаеш. цял ден ти се щяло нещичко да хапнеш, легнеш вечер гладен и — хоп — насън виждаш богата трапеза. и хапнеш, и сръбнеш. никой ти не виква. никой те не ритва ето оназ вечер какъв сън сънувах вървя с наша данка. стигаме до моста. изведнъж усещам, че някой ме дръпва и така ми казва — пардон, господине! вие нали бяхте стихоплетът джафко? аз се понавъсвам. отвръщам сърдито — не съм стихоплетът, а поетът джафко. за какво ти трябвам? — извинете, моля. едно писмо нося. царят ви го праща. аз питам учуден? — кой цар ми го праща? — царят, що владее кучешкото царство. отварям писмото. чета и не зная от радост къде съм. — драги ми поете — пише ми сам царят, — с наслада ти четох днеска стиховете. и те назначавам придворен учител. ела тук веднага. че на царедворци чакат синовете, за да ги направиш всичките поети! подавам писмото на дана и казвам — на, чети, да видиш каква чест ми правят, та и ти да знаеш как да ме зачиташ. а сега прощавай! при царя отивам. дигам глава гордо. с пратеника тръгвам. пристигаме скоро в школото на царя. там сварвам чедата на видните псета. като ме съзряха, зашепнаха тихо поета, поета! сам царят ме среща. аз му се покланям. — благодаря, царю, за честта голяма. за мене по-драга от таз служба няма. но тясно е тука, о, царю честити, за мойта наука. вънка на открито трябва да излязат моите ученици. и волни да бъдат като горски птици. по двор и градини, в гори и долини да тичат, да скачат. с мене да играят. и аз ще ги уча що трябва да знаят. тука ще се връщат всички изгладнели. та ядене царско за вечер гласете! и царят знак дава! — да бъде, поете! и радост голяма тогава настава. на възбог ме дигат моите ученици и скачат, и викат — учителю драги, жив и здрав бъди ни! по-скоро навънка! по-скоро води ни в царските градини! но един глас страшен най-силно крещеше — навънка! навънка! и аз се събудих. готвачката деша викаше сърдито — вънка, вънка, вънка! легнал ми в леглото! ах, джафко проклети! и тя ме изрита. но аз й прощавам. че тя знае само да пържи кюфтета. затова тъй грубо съня ми прекъсна. но от туй той още по-сладък ми стана. и аз ще го помня, докато живея!\n",
       "\n",
       "Enhancing Information:\n",
       "\n",
       "**кратко резюме на историята:** Историята разказва за кучето на име Джафко, което размишлява за сладостта на мечтите в сравнение с любовта си към месото. То мечтае да бъде назначено за кралски учител на децата на краля, наслаждавайки се на свободата и радостта от преподаването на открито. Въпреки това, мечтата му е внезапно прекъсната от готвача, когото в крайна сметка прощава, като още повече цени сладостта на своята мечта.\n",
       "\n",
       "**главни герои:** Джафко (кучето), кралят, Данка (спътник), Деша (готвачката).\n",
       "\n",
       "**местоположение:** Историята се развива в приказно кучешко кралство, основно в училището на краля и околните градини.\n",
       "\n",
       "**поучение:** Историята предава, че мечтите могат да бъдат по-пълноценни и сладки от реалността, а прекъсванията в живота могат да доведат до по-голямо оценяване на тези мечти."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(db.get('2')[\"documents\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "врабчето си иска зърното: сивото врабче кацнало върху един плет и почнало да си ниже герданче от мънистени зрънца. както нижело, изтървало едно зърно. зърното паднало в тръните, търколило се някъде и се загубило. — хей, плет — изчуруликало врабчето, — дай ми мънистеното зърно или ще кажа на огъня да те изгори! — кажи му де! — отвърнал плетът. — огънчо — хвръкнало врабчето над огъня, — изгори плета! — не ща — отвърнал огънят. — докато си имам сухи букови дървета, много ми е притрябвало да горя трънливия плет и да се бода на тръните му. — ще кажа на реката да те угаси! — кажи й де! — отвърнал огънят. врабчето литнало над реката и зачуруликало. — речице, моля ти се, угаси огъня! — ами — отговорила реката, — много ми е притрябвало да гася огън. додето си имам тия гладки камъчета, които сега броя, що ми трябва да се паря с огън? — ще кажа на бивола да те изпие! — заканило се врабчето. — кажи му де! — биволчо, изпий реката! — кацнало врабчето върху единия рог на бивола. — как не — отвърнал биволът, — аз се напасох с такава росна трева, че ако сръбна и вода — ще ми се надуе коремът и ще се пукне. — тогава ще кажа на вълка да те изяде. — кажи му де! — рекъл биволът. врабчето отишло при вълка в гората. — вълчо — помолило го то, — ела да изядеш бивола. — какво приказваш — отговорил вълкът, — додето има такива крехки агънца, що ми трябва жилаво биволско месо! — ще кажа на овчаря да насъска кучетата и те ще ти разкъсат кожуха! — кажи му де! —\n",
       "\n",
       "Contextual Information:\n",
       "\n",
       "Този фрагмент описва как сивото врабче търси изгубеното си зърно и заплашва различни природни елементи (плет, огън, река, бивол, вълк, овчар), за да го получи обратно. В края на историята, след множество заплахи и взаимодействия, врабчето получава зърното и се радва. Този откъс е част от по-голям разказ, който илюстрира темата за взаимопомощ и последователността на действията в природата.\n",
       "\n",
       "Enhancing Information:\n",
       "\n",
       "**кратко резюме на историята:** Сивият врабец губи мънисто, докато ги нанизва на ограда, и иска да му бъде върнато, заплашвайки различни елементи на природата. Всяко същество отказва да се подчинява, което води до верижна реакция от заплахи, докато не се намесва котка, предизвиквайки серия от събития, които в крайна сметка водят до това врабецът да си върне мънистото от оградата.  \n",
       "**главни герои:** Сивият врабец, оградата, огънят, реката, биволът, вълкът, овчарят, мишките и котката.  \n",
       "**местоположение:** Природна среда с ограда, огън, река и околна дива природа.  \n",
       "**поучение:** Историята илюстрира безсмислието на заплахите и взаимовръзката в природата, подчертавайки, че сътрудничеството и разбирането са по-ефективни от заплашването."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(db.get('3')[\"documents\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "бивола. — какво приказваш — отговорил вълкът, — додето има такива крехки агънца, що ми трябва жилаво биволско месо! — ще кажа на овчаря да насъска кучетата и те ще ти разкъсат кожуха! — кажи му де! — обърнал се вълкът. — овчарко — викнало отдалече врабчето, — проводи кучетата да изядат вълка! — дордето имам в торбата си мек хляб, защо ми трябва да провождам кучетата да си трошат зъбите с кораво вълче месо — отговорил овчарят. — но аз ще кажа на мишките да ти изгризат торбата! — кажи им де! — мишки — надникнало врабчето в една миша дупка, — излезте да изгризете кожената торба на овчаря! — додето си имаме зърно в житницата, торба няма да гризем — отговорили мишките. тогава врабчето заплакало. видяла го една котка и го попитала — защо плачеш, врабченце? я млъкни! недей натъжава котешкото ми сърце. — ще млъкна, ако изядеш мишките. изведнъж котката се хвърлила върху мишките, мишките — върху торбата на овчаря, овчарят насъскал кучетата си подир вълка, вълкът подгонил бивола, биволът се навел да изпие реката, реката потекла към огъня, огънят запалил единия край на трънения плет, плетът се уплашил и за да не изгори, намерил мънистеното зърно и го дал на врабчето. врабчето се зарадвало много, кацнало на едно клонче, весело зачуруликало и всички се укротили.\n",
       "\n",
       "Contextual Information:\n",
       "Този фрагмент представлява част от историята за врабчето, което търси своето мънистено зърно, и описва взаимодействията между различни животни, включително вълка, бивола, овчаря и мишките, в опитите им да решат конфликта. В края на този епизод, врабчето получава зърното си, след като различните герои реагират на заплахите и молбите му.\n",
       "\n",
       "Enhancing Information:\n",
       "**кратко резюме на историята:** Сивото врабче загубва мънистено зърно и заплашва различни същества, за да го получи обратно. След серия от заплахи, всички се обединяват, за да помогнат на врабчето, което в крайна сметка получава зърното си.\n",
       "\n",
       "**главни герои:** Сивото врабче, плетът, огънят, реката, биволът, вълкът, овчарят, мишките, котката.\n",
       "\n",
       "**местоположение:** Природна среда с плет, огън, река, гора и полета.\n",
       "\n",
       "**морал:** Заплахите и конфликти могат да доведат до сътрудничество и решаване на проблеми, а истинската помощ идва от обединението на различни същества."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import display, Markdown, Latex\n",
    "# display(Markdown(db.get('82b05836-67ed-49f9-ad25-d51c36c5b038')[\"documents\"][0]))\n",
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(db.get('82b05836-67ed-49f9-ad25-d51c36c5b038')[\"documents\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "бивола. — какво приказваш — отговорил вълкът, — додето има такива крехки агънца, що ми трябва жилаво биволско месо! — ще кажа на овчаря да насъска кучетата и те ще ти разкъсат кожуха! — кажи му де! — обърнал се вълкът. — овчарко — викнало отдалече врабчето, — проводи кучетата да изядат вълка! — дордето имам в торбата си мек хляб, защо ми трябва да провождам кучетата да си трошат зъбите с кораво вълче месо — отговорил овчарят. — но аз ще кажа на мишките да ти изгризат торбата! — кажи им де! — мишки — надникнало врабчето в една миша дупка, — излезте да изгризете кожената торба на овчаря! — додето си имаме зърно в житницата, торба няма да гризем — отговорили мишките. тогава врабчето заплакало. видяла го една котка и го попитала — защо плачеш, врабченце? я млъкни! недей натъжава котешкото ми сърце. — ще млъкна, ако изядеш мишките. изведнъж котката се хвърлила върху мишките, мишките — върху торбата на овчаря, овчарят насъскал кучетата си подир вълка, вълкът подгонил бивола, биволът се навел да изпие реката, реката потекла към огъня, огънят запалил единия край на трънения плет, плетът се уплашил и за да не изгори, намерил мънистеното зърно и го дал на врабчето. врабчето се зарадвало много, кацнало на едно клонче, весело зачуруликало и всички се укротили.\n",
       "\n",
       "Contextual Information:\n",
       "\n",
       "Този откъс е част от приказка, в която врабчето се опитва да си върне изгубеното мънистено зърно, като заплашва различни животни и обекти с верига от действия, които водят до хаос, докато накрая всички се успокояват и врабчето получава зърното си обратно.\n",
       "\n",
       "Enhancing Information:\n",
       "\n",
       "**brief summary of the story:** Сивото врабче изпуска мънистено зърно в тръните и се опитва да го върне, като заплашва различни елементи от природата и животни, но никой не се съгласява да помогне. Накрая котката се намесва, което предизвиква верижна реакция, водеща до връщането на зърното на врабчето.  \n",
       "**main characters:** Врабчето, плетът, огънят, реката, биволът, вълкът, овчарят, мишките, котката.  \n",
       "**setting:** Природна среда с плет, огън, река, гора и животни.  \n",
       "**moral:** Упоритостта и настойчивостта могат да доведат до успех, дори когато изглежда, че никой не иска да помогне."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(db.get('b84b6c61-c932-4d16-9336-9406c62c8e13')[\"documents\"][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Подобряване на информацията: кратко резюме на историята: Сивият врабец губи мънисто, докато ги нанизва на ограда, и иска да му бъде върнато, заплашвайки различни елементи на природата. Всяко същество отказва да се подчинява, което води до верижна реакция от заплахи, докато не се намесва котка, предизвиквайки серия от събития, които в крайна сметка водят до възстановяването на изгубеното мънисто от оградата.\n",
       "\n",
       "главни герои: Сивият врабец, оградата, огънят, реката, биволът, вълкът, овчарят, мишките и котката.\n",
       "\n",
       "обстановка: Историята се развива в естествена среда, включваща ограда, огън, река и гора.\n",
       "\n",
       "морал: Историята илюстрира безсмислието на заплахите и взаимовръзката в природата, подчертавайки, че сътрудничеството и разбирането са по-ефективни от заплашването."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = llm.invoke(\"\"\"Translate the following text into Bulgarian. Please adhere to these guidelines:\n",
    "\n",
    "1. Maintain the original meaning and tone.\n",
    "2. Avoid word-for-word translation; focus on natural Bulgarian phrasing.\n",
    "3. Use diverse vocabulary to prevent repetition of words or phrases.\n",
    "4. Preserve any formatting or structure present in the original text.\n",
    "5. If there are specialized terms, provide the most appropriate Bulgarian equivalent.\n",
    "6. Ensure the translation aligns with Bulgarian cultural context where applicable.\n",
    "\n",
    "<text>\n",
    "Enhancing Information: brief summary of the story: A gray sparrow loses a bead while stringing them on a fence and demands it back, threatening various elements of nature. Each entity refuses to comply, leading to a chain reaction of threats until a cat intervenes, causing a series of events that ultimately results in the sparrow retrieving its lost bead from the fence.\n",
    "\n",
    "main characters: The gray sparrow, the fence, the fire, the river, the buffalo, the wolf, the shepherd, the mice, and the cat.\n",
    "\n",
    "setting: The story takes place in a natural environment featuring a fence, a fire, a river, and a forest.\n",
    "\n",
    "moral: The story illustrates the futility of threats and the interconnectedness of nature, emphasizing that cooperation and understanding are more effective than intimidation.\n",
    "</text>\n",
    "\n",
    "Please provide only the Bulgarian translation without any additional comments.\"\"\")\n",
    "\n",
    "display(Markdown(response.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Морал: Историята илюстрира безсмислието на заплахите и взаимовръзката в природата, подчертавайки, че сътрудничеството и разбирането са по-ефективни от заплахите.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "морал: Историята илюстрира безсмислието на заплахите и взаимосвързаността на природата, подчертавайки, че сътрудничеството и разбирането са по-ефективни от сплашването.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepL translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api-free.deepl.com/v2/translate\"\n",
    "headers = {\n",
    "    \"Authorization\": \"DeepL-Auth-Key 3afd0c9a-0aa4-9220-6227-778e77bcfc64:fx\",\n",
    "    \"User-Agent\": \"YourApp/1.2.3\"\n",
    "}\n",
    "\n",
    "def deepl_translate_batch(text_list):\n",
    "    data = {\n",
    "        \"text\": text_list,\n",
    "        \"target_lang\": \"EN\",\n",
    "        \"source_lang\": \"BG\"\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_json = json.loads(response.text)\n",
    "    return [trans['text'] for trans in response_json['translations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здравей, свят!\n"
     ]
    }
   ],
   "source": [
    "import deepl\n",
    "\n",
    "auth_key = \"3afd0c9a-0aa4-9220-6227-778e77bcfc64:fx\"  # Replace with your key\n",
    "translator = deepl.Translator(auth_key)\n",
    "\n",
    "result = translator.translate_text(\"Hello, world!\", target_lang=\"BG\")\n",
    "print(result.text)  # \"Bonjour, le monde !\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairy_tale_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
